{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code aims at converting tensor back to text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import collections\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./saved_models/qq/', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.load('./pred_result/qq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'bio', 'type', 'recover', 'loss', 'id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkandvote(sent, recovers, bios, dtypes):\n",
    "    mapping_bio = ['B', 'I', 'O']\n",
    "    mapping_type = ['P', 'C', 'MC']\n",
    "    \n",
    "    \n",
    "    recover_sent, recover_bio = [], []\n",
    "    adu_type = []\n",
    "    count = 0\n",
    "    \n",
    "    last = torch.rand(3)\n",
    "    for index, (word, r, bio, dtype) in enumerate(zip(sent[1:], recovers[1:], bios[1:-1], dtypes[1:])):\n",
    "        if(r and word[:2]=='##'):\n",
    "            if(bio==0):\n",
    "                adu_type.append(\n",
    "                    mapping_type[last.argmax(-1).item()]\n",
    "                )\n",
    "                last = torch.zeros_like(dtype)\n",
    "                recover_bio[-1] = mapping_bio[bio]\n",
    "                count += 1\n",
    "                \n",
    "            recover_sent[-1] += word.split('#')[-1]\n",
    "        else:\n",
    "            if(bio==0):\n",
    "                adu_type.append(\n",
    "                    mapping_type[last.argmax(-1).item()]\n",
    "                )\n",
    "                last = torch.zeros_like(dtype)\n",
    "                count += 1\n",
    "\n",
    "            recover_sent.append(word)\n",
    "            recover_bio.append(mapping_bio[bio])\n",
    "\n",
    "        if(bio<=1):\n",
    "            last += dtype\n",
    "    else:\n",
    "        adu_type.append(\n",
    "            mapping_type[last.argmax(-1).item()]\n",
    "        )\n",
    "    assert count==(len(adu_type)-1)\n",
    "    return recover_sent, recover_bio, adu_type[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60\n",
      "i B\n",
      "do I\n",
      "n I\n",
      "' I\n",
      "t I\n",
      "see I\n",
      "any I\n",
      "reason I\n",
      "not I\n",
      "to I\n",
      "institute I\n",
      "mandatory I\n",
      "background I\n",
      "checks I\n",
      "( O\n",
      "which O\n",
      "red O\n",
      "flags O\n",
      "from O\n",
      "the O\n",
      "background O\n",
      "check O\n",
      "would O\n",
      "make O\n",
      "you O\n",
      "ineligible O\n",
      "is O\n",
      "another O\n",
      "issue O\n",
      ") O\n",
      "or B\n",
      "institute I\n",
      "some I\n",
      "sort I\n",
      "of I\n",
      "gun I\n",
      "license I\n",
      "so I\n",
      "long I\n",
      "as I\n",
      "the I\n",
      "fee I\n",
      "is I\n",
      "not I\n",
      "exorbitant I\n",
      "and I\n",
      "the I\n",
      "process I\n",
      "for I\n",
      "applying I\n",
      "for I\n",
      "the I\n",
      "license I\n",
      "is I\n",
      "not I\n",
      "too I\n",
      "difficult I\n",
      "or I\n",
      "restrictive I\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "index = 12\n",
    "temp = checkandvote(\n",
    "    tokenizer.convert_ids_to_tokens(pred['id'][index].tolist()), \n",
    "    pred['recover'][index].tolist(), pred['bio'][index],\n",
    "    torch.tensor(pred['type'][index]).softmax(-1)\n",
    "   )\n",
    "\n",
    "print(len(temp[0]), len(temp[1]))\n",
    "for word, bio in zip(temp[0], temp[1]):\n",
    "    print(word, bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the begin\n",
    "def checkforbegin(pred):\n",
    "    for side in range(2):\n",
    "        for index in range(len(pred[side]['id'])):\n",
    "            last = [[2,1]]\n",
    "            acc = [[0,0,0]]\n",
    "            for word, bio, r in zip(tokenizer.convert_ids_to_tokens(pred[side]['id'][index].tolist()[1:]), pred[side]['bio'][index][1:], pred[side]['recover'][index].tolist()[1:]):\n",
    "                if(bio==0 and r>0 and word[:2]=='##'):\n",
    "                    for _ in last:\n",
    "                        pass\n",
    "                        if(_[0] == 0 or _[1] =='.'):\n",
    "                            break\n",
    "                    else:\n",
    "                        print(side, index)\n",
    "                #if(r>0):\n",
    "                #    last.append([bio, word])\n",
    "                if(r==0):\n",
    "                    last = [[bio, word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recover = [\n",
    "    {'sent':[], 'bio':[], 'index':[],'type':[]},\n",
    "    {'sent':[], 'bio':[], 'index':[],'type':[]}\n",
    "]\n",
    "\n",
    "for side in range(2):\n",
    "    for index in range(len(pred[side]['id'])):\n",
    "        temp = checkandvote(\n",
    "                        tokenizer.convert_ids_to_tokens(pred[side]['id'][index].tolist()), \n",
    "                        pred[side]['recover'][index].tolist(), pred[side]['bio'][index],\n",
    "                        torch.tensor(pred_type[side]['type'][index]).softmax(-1)\n",
    "                       )\n",
    "        \n",
    "        recover[side]['sent'].append(' '.join(temp[0]))\n",
    "        recover[side]['bio'].append(temp[1])\n",
    "        recover[side]['type'].append(temp[2])\n",
    "        recover[side]['index'].append(pred[side]['index'][index].item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate sequence B\n",
    "for side in range(2):\n",
    "    for r_index in range(len(recover[side]['bio'])):\n",
    "        for index in range( len(recover[side]['bio'][r_index])-1, 0, -1):\n",
    "            if( recover[side]['bio'][r_index][index]=='B' and recover[side]['bio'][r_index][index-1]=='B' ):\n",
    "                recover[side]['bio'][r_index][index]='I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removec last punctation\n",
    "checklist = ['and', 'or']\n",
    "for side in range(2):\n",
    "    for r_index in range(len(recover[side]['bio'])):\n",
    "        for index in range( len(recover[side]['bio'][r_index])-1):\n",
    "            if( recover[side]['bio'][r_index][index]=='I' and recover[side]['bio'][r_index][index+1]!='I'):\n",
    "                sent = recover[side]['sent'][r_index].split()\n",
    "                if((sent[index] in string.punctuation) or (sent[index] in checklist)):\n",
    "                    recover[side]['bio'][r_index][index]='O'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "for side in range(2):\n",
    "    for index in range(len(recover[side]['sent'])):\n",
    "        sent = recover[side]['sent'][index].split()\n",
    "        bio = recover[side]['bio'][index]\n",
    "        for windex in range(len(sent[:-1])):\n",
    "            if( bio[windex]=='B' and bio[windex+1]=='B'):\n",
    "                \n",
    "                print(side, index)\n",
    "                print(sent[max(windex-4,0):windex+4])\n",
    "                print(bio[max(windex-4,0):windex+4])\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 313901\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 313957\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314018\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314073\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314139\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314203\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314261\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314314\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314378\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314441\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314510\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314567\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314627\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "0 314685\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340191\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340285\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340366\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340422\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340484\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340543\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340637\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340696\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340769\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340837\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 340910\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 341007\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 341123\n",
      "\n",
      "15\n",
      "['facebook', 'and', 'twitter', 'make', 'this', 'process', 'way', 'easier']\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "1 341195\n"
     ]
    }
   ],
   "source": [
    "def checkandprint(check, arr, post, bios):\n",
    "    arr = ' '.join(arr)\n",
    "    key = 'facebook'\n",
    "    l = len(key.split())\n",
    "    if(arr == key):\n",
    "        for index in range(len(post)-l):\n",
    "            if(' '.join(post[index:index+l]) == key and bios[index]=='B' and bios[index+l]=='O'):\n",
    "                print()\n",
    "                print(index)\n",
    "                print(post[index:index+8])\n",
    "                print(bios[index:index+8])\n",
    "                \n",
    "                check[''.join(bios[index:index+4])] += 1\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "check = collections.defaultdict(int)\n",
    "length = 8\n",
    "for side in range(2):\n",
    "    for index in range(len(recover[side]['sent'])):\n",
    "        buffer = []\n",
    "        for word, bio in zip(recover[side]['sent'][index].split(),recover[side]['bio'][index]):\n",
    "            if(bio == 'B'):\n",
    "                if(len(buffer)):\n",
    "                    if(checkandprint(check, buffer[:length], recover[side]['sent'][index].split(),recover[side]['bio'][index])):\n",
    "                        print(side, index)\n",
    "                    \n",
    "            if(bio == 'B' or bio == 'I'):\n",
    "                buffer.append(word)\n",
    "        else:\n",
    "            if(bio == 'B'):\n",
    "                if(len(buffer)):\n",
    "                    if(checkandprint(check, buffer[:length], recover[side]['sent'][index].split(),recover[side]['bio'][index])):\n",
    "                        print(side, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "stat = []\n",
    "for _ in range(2):\n",
    "    stat.append([collections.defaultdict(int) for _ in range(length)])\n",
    "    \n",
    "def adddict(dataset, words, length, front=True):\n",
    "    l = min(len(buffer), length)\n",
    "    if(front):\n",
    "        dataset[l-1][' '.join(buffer[:l])] += 1\n",
    "    else:\n",
    "        dataset[l-1][' '.join(buffer[-l:])] += 1\n",
    "    \n",
    "for side in range(2):\n",
    "    for index in range(len(recover[side]['sent'])):\n",
    "        buffer = []\n",
    "        for word, bio in zip(recover[side]['sent'][index].split(),recover[side]['bio'][index]):\n",
    "            if(bio == 'B'):\n",
    "                if(len(buffer)):\n",
    "                    adddict(stat[0], buffer, length, True)\n",
    "                    adddict(stat[1], buffer, length, False)\n",
    "                                        \n",
    "            if(bio == 'B' or bio == 'I'):\n",
    "                buffer.append(word)\n",
    "        else:\n",
    "            if(bio == 'B'):\n",
    "                if(len(buffer)):\n",
    "                    adddict(stat[0], buffer, length, True)\n",
    "                    adddict(stat[1], buffer, length, False)\n",
    "                    \n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(length):\n",
    "        stat[i][j] = sorted([(key, value) for key, value in stat[i][j].items()], key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"you ' re\", 304),\n",
       " ('the problem is', 140),\n",
       " ('i do not', 136),\n",
       " (\"it ' s\", 120),\n",
       " (\"i ' m\", 88),\n",
       " ('it is not', 82),\n",
       " (\"that ' s\", 77),\n",
       " (\"i ' d\", 74),\n",
       " ('this is true', 72),\n",
       " ('it does not', 70),\n",
       " (\"let ' s\", 48),\n",
       " ('i did not', 40),\n",
       " ('the point is', 38),\n",
       " ('that makes sense', 37),\n",
       " ('not at all', 35),\n",
       " ('you are correct', 32),\n",
       " ('in the past', 30),\n",
       " ('you are right', 29),\n",
       " ('this is false', 28),\n",
       " ('it all rhymes', 28),\n",
       " ('source of powers', 28),\n",
       " ('as an adult', 26),\n",
       " ('it makes sense', 25),\n",
       " ('the difference is', 24),\n",
       " ('this is wrong', 23),\n",
       " ('you could argue', 23),\n",
       " ('when it comes', 23),\n",
       " ('are you saying', 23),\n",
       " ('this is nonsense', 19),\n",
       " ('that sounds awful', 19),\n",
       " ('this is ridiculous', 19),\n",
       " ('this one is', 19),\n",
       " ('i have read', 18),\n",
       " ('it was lgbt', 18),\n",
       " ('it is true', 17),\n",
       " ('in this case', 16),\n",
       " ('this makes sense', 16),\n",
       " ('quality also suffers', 16),\n",
       " ('i can see', 15),\n",
       " ('i i feel', 15),\n",
       " ('it bothers me', 14),\n",
       " ('i am not', 14),\n",
       " ('developing countries lose', 14),\n",
       " ('even without context', 14),\n",
       " ('you just had', 14),\n",
       " ('you did not', 13),\n",
       " ('lobbying would increase', 13),\n",
       " ('this is not', 13),\n",
       " ('are you serious', 13),\n",
       " ('what would change', 13),\n",
       " ('why not both', 13),\n",
       " ('if that is', 12),\n",
       " (\"hillary ' s\", 12),\n",
       " ('it also bothers', 12),\n",
       " ('we condemn it', 12),\n",
       " ('i am saddened', 12),\n",
       " ('he gained power', 12),\n",
       " ('the reality is', 11),\n",
       " ('at that point', 11),\n",
       " ('do you think', 11),\n",
       " ('you can argue', 11),\n",
       " ('in the us', 10),\n",
       " ('use in math', 10),\n",
       " ('rape is wrong', 10),\n",
       " ('during the 1930s', 10),\n",
       " ('think of it', 10),\n",
       " ('one could argue', 10),\n",
       " ('sure there is', 10),\n",
       " ('i play poker', 10),\n",
       " ('this is rediculous', 10),\n",
       " ('you can not', 10),\n",
       " ('world war ii', 10),\n",
       " ('i am adopted', 10),\n",
       " ('it is comfortable', 10),\n",
       " ('the end was', 10),\n",
       " ('calzones reduce wast', 10),\n",
       " ('it could be', 10),\n",
       " ('at this point', 10),\n",
       " ('this would help', 10),\n",
       " ('before that deployment', 10),\n",
       " ('i understand this', 9),\n",
       " ('i would actually', 9),\n",
       " (\"do ' t\", 9),\n",
       " ('i like musicals', 9),\n",
       " ('in the uk', 9),\n",
       " ('the issue is', 9),\n",
       " ('invisible disabilities exist', 9),\n",
       " ('do you have', 9),\n",
       " ('my problem is', 9),\n",
       " ('this is unfair', 9),\n",
       " ('death pushes us', 9),\n",
       " ('graveyards are disgusting', 9),\n",
       " ('we could say', 9),\n",
       " ('i am here', 8),\n",
       " ('as a canadian', 8),\n",
       " ('to some extent', 8),\n",
       " ('it is sad', 8),\n",
       " ('you are saying', 8),\n",
       " ('a scientific consensus', 8),\n",
       " ('as an american', 8),\n",
       " ('it would be', 8),\n",
       " ('this is there', 8),\n",
       " ('i voted remain', 8),\n",
       " ('some girls say', 8),\n",
       " ('you know them', 8),\n",
       " ('in most cases', 8),\n",
       " ('i was not', 8),\n",
       " ('she has writers', 8),\n",
       " ('it was not', 8),\n",
       " ('there are many', 8),\n",
       " ('at the moment', 8),\n",
       " ('there are exceptions', 8),\n",
       " ('do you believe', 8),\n",
       " ('porn is wrong', 8),\n",
       " ('this is murder', 8),\n",
       " ('nothing adds up', 8),\n",
       " ('this failed colossally', 8),\n",
       " ('in us politics', 8),\n",
       " ('humanities are worthless', 8),\n",
       " ('the south went', 8),\n",
       " ('prevention , which', 8),\n",
       " ('loosing potential knowledge', 8),\n",
       " ('love is real', 8),\n",
       " ('you are arguing', 7),\n",
       " ('it frustrates me', 7),\n",
       " ('this is it', 7),\n",
       " ('your view is', 7),\n",
       " ('this is i', 7),\n",
       " ('i completely disagree', 7),\n",
       " ('it is harmful', 7),\n",
       " ('the term states', 7),\n",
       " ('this is crazy', 7),\n",
       " ('this is illegal', 7),\n",
       " ('littering is unpleasant', 7),\n",
       " ('i agree with', 7),\n",
       " ('most people do', 7),\n",
       " ('think about it', 7),\n",
       " ('you do realize', 7),\n",
       " ('it can be', 7),\n",
       " ('you did it', 7),\n",
       " ('does not compute', 7),\n",
       " ('avatar was good', 7),\n",
       " ('are you kidding', 7),\n",
       " ('genetics / disorders', 7),\n",
       " ('as a starting', 6),\n",
       " ('this sounds harsh', 6),\n",
       " ('of particular irritation', 6),\n",
       " ('they should not', 6),\n",
       " ('why should they', 6),\n",
       " ('i have ocd', 6),\n",
       " ('i doubt it', 6),\n",
       " ('are there i', 6),\n",
       " ('it is mental', 6),\n",
       " ('bruce is wiser', 6),\n",
       " ('it is divisive', 6),\n",
       " ('i hear you', 6),\n",
       " ('to most easily', 6),\n",
       " ('you say that', 6),\n",
       " ('this is a', 6),\n",
       " ('we can eat', 6),\n",
       " ('helping the disadvantaged', 6),\n",
       " ('yes there is', 6),\n",
       " ('is it stupid', 6),\n",
       " ('i completely agree', 6),\n",
       " ('this does not', 6),\n",
       " ('luigi is green', 6),\n",
       " ('luigi is monogamous', 6),\n",
       " ('luigi is taller', 6),\n",
       " ('in any case', 6),\n",
       " ('greece is fucked', 6),\n",
       " ('i love rap', 6),\n",
       " ('here is let', 6),\n",
       " ('i enjoy working', 6),\n",
       " ('that is true', 6),\n",
       " ('this thread had', 6),\n",
       " ('your point is', 6),\n",
       " ('yes it is', 6),\n",
       " ('i touched the', 6),\n",
       " ('i kind of', 6),\n",
       " ('do you mean', 6),\n",
       " ('i hate them', 6),\n",
       " ('the label matters', 6),\n",
       " ('you could recycle', 6),\n",
       " ('we already recycle', 6),\n",
       " (\"what ' s\", 6),\n",
       " ('acting is cool', 6),\n",
       " ('lying is acting', 6),\n",
       " ('many successful actors', 6),\n",
       " ('acting is stupid', 6),\n",
       " ('it was entertaining', 6),\n",
       " ('given all this', 6),\n",
       " ('i am very', 6),\n",
       " ('what defines fanservice', 6),\n",
       " ('it would seem', 6),\n",
       " ('this is irrelevant', 6),\n",
       " ('how do you', 6),\n",
       " ('there are 460', 6),\n",
       " ('i heard this', 6),\n",
       " ('it helps foster', 6),\n",
       " ('some people said', 6),\n",
       " ('what is the', 6),\n",
       " ('i listed mistborn', 6),\n",
       " ('marriage is confining', 6),\n",
       " ('why worship lucifer', 6),\n",
       " ('the bible has', 6),\n",
       " ('does not matter', 6),\n",
       " ('china will object', 6),\n",
       " ('the flaw in', 6),\n",
       " ('humans are richer', 6),\n",
       " ('the solution is', 6),\n",
       " ('they are herbivores', 6),\n",
       " ('if you want', 6),\n",
       " ('i am insignificant', 6),\n",
       " ('by making the', 6),\n",
       " ('there is less', 6),\n",
       " ('this is unrealistic', 6),\n",
       " ('even good people', 6),\n",
       " ('we are both', 6),\n",
       " ('it amounts to', 6),\n",
       " ('i wan na', 6),\n",
       " ('they did not', 5),\n",
       " ('at the same', 5),\n",
       " ('it is wrong', 5),\n",
       " ('i do agree', 5),\n",
       " ('if we agree', 5),\n",
       " ('you have to', 5),\n",
       " ('people are saying', 5),\n",
       " ('they absolutely are', 5),\n",
       " ('murder is wrong', 5),\n",
       " ('at the time', 5),\n",
       " ('i i still', 5),\n",
       " ('their defense is', 5),\n",
       " ('it is my', 5),\n",
       " ('do you agree', 5),\n",
       " ('this is interesting', 5),\n",
       " ('i am i', 5),\n",
       " ('based on what', 5),\n",
       " ('there is not', 5),\n",
       " ('you should not', 5),\n",
       " ('incest is unnatural', 5),\n",
       " ('i do understand', 5),\n",
       " ('it absolutely does', 5),\n",
       " ('teachers get flack', 5),\n",
       " ('learn to improvise', 5),\n",
       " ('this is ludicrous', 5),\n",
       " ('what you are', 5),\n",
       " ('marginal rates matter', 5),\n",
       " ('i accept that', 5),\n",
       " ('it should not', 5),\n",
       " ('the truth is', 5),\n",
       " ('i i also', 5),\n",
       " ('it is rude', 5),\n",
       " ('for most people', 5),\n",
       " ('look at it', 5),\n",
       " ('outside of statistics', 5),\n",
       " ('my point is', 5),\n",
       " ('demand is irregular', 5),\n",
       " ('sexting is complicated', 5),\n",
       " ('you are wrong', 5),\n",
       " ('you do understand', 5),\n",
       " ('the treatment works', 5),\n",
       " ('my so it', 5),\n",
       " ('do you admit', 5),\n",
       " ('it is clear', 5),\n",
       " ('you are thinking', 5),\n",
       " ('one problem is', 5),\n",
       " ('poetry is art', 5),\n",
       " ('this always baffles', 4),\n",
       " ('college is important', 4),\n",
       " ('college is free', 4),\n",
       " ('i fear death', 4),\n",
       " ('a football cmv', 4),\n",
       " ('it just does', 4),\n",
       " ('i would give', 4),\n",
       " ('are you balding', 4),\n",
       " ('i want that', 4),\n",
       " ('i should not', 4),\n",
       " ('show them kindness', 4),\n",
       " ('you are presuming', 4),\n",
       " ('it seems to', 4),\n",
       " ('what about it', 4),\n",
       " ('if some sort', 4),\n",
       " ('causation this is', 4),\n",
       " ('terrorism is relative', 4),\n",
       " ('superman is boring', 4),\n",
       " ('criminal justice system', 4),\n",
       " ('cheating is bad', 4),\n",
       " ('many will say', 4),\n",
       " ('people are interdependent', 4),\n",
       " ('people travel around', 4),\n",
       " ('i like it', 4),\n",
       " ('like freudian psychoanalysis', 4),\n",
       " ('vaccines are dangerous', 4),\n",
       " ('i ended up', 4),\n",
       " (\"trump ' s\", 4),\n",
       " ('i would agree', 4),\n",
       " ('my gut feeling', 4),\n",
       " ('it did not', 4),\n",
       " ('i am canadian', 4),\n",
       " ('what about them', 4),\n",
       " ('no close border', 4),\n",
       " ('they are not', 4),\n",
       " ('you changed my', 4),\n",
       " ('it is barbaric', 4),\n",
       " ('religion in general', 4),\n",
       " ('lacrosse is bad', 4),\n",
       " ('cooking is bad', 4),\n",
       " ('how do i', 4),\n",
       " ('football is boring', 4),\n",
       " ('neither do i', 4),\n",
       " ('does this mean', 4),\n",
       " ('our local school', 4),\n",
       " ('careful sauce application', 4),\n",
       " ('what about inflation', 4),\n",
       " ('talking about bernie', 4),\n",
       " ('i love economics', 4),\n",
       " ('probably most importantly', 4),\n",
       " ('i would disagree', 4),\n",
       " ('this is what', 4),\n",
       " ('as a child', 4),\n",
       " ('i hate driving', 4),\n",
       " ('why the eu', 4),\n",
       " ('humans are omnivores', 4),\n",
       " ('this is dramatic', 4),\n",
       " ('i just did', 4),\n",
       " ('the argument that', 4),\n",
       " ('the only thing', 4),\n",
       " ('my title sucked', 4),\n",
       " ('your argument is', 4),\n",
       " ('at the very', 4),\n",
       " ('caning seems ideal', 4),\n",
       " ('you do realise', 4),\n",
       " ('the idea is', 4),\n",
       " ('how many miles', 4),\n",
       " ('all languages it', 4),\n",
       " ('the american revolution', 4),\n",
       " ('being an asshole', 4),\n",
       " ('words are important', 4),\n",
       " ('it is plausible', 4),\n",
       " ('that does not', 4),\n",
       " ('the lighting changed', 4),\n",
       " ('i can not', 4),\n",
       " ('what is acting', 4),\n",
       " (\"they ' re\", 4),\n",
       " ('why is that', 4),\n",
       " ('makeshift chopsticks work', 4),\n",
       " ('i truly do', 4),\n",
       " ('it is superfluous', 4),\n",
       " ('life is meaningless', 4),\n",
       " ('this bothers me', 4),\n",
       " ('as for konami', 4),\n",
       " ('dota is readable', 4),\n",
       " ('they are notoriously', 4),\n",
       " ('vaccination saves lives', 4),\n",
       " ('i am american', 4),\n",
       " ('i miss understood', 4),\n",
       " ('i like evernote', 4),\n",
       " (\"i ' ve\", 4),\n",
       " ('you if you', 4),\n",
       " ('sun in the', 4),\n",
       " ('are you suggesting', 4),\n",
       " ('as a dog', 4),\n",
       " ('extensive urban development', 4),\n",
       " ('literacy is important', 4),\n",
       " ('i am a', 4),\n",
       " ('people would mischaracterize', 4),\n",
       " ('i can appreciate', 4),\n",
       " ('i could agree', 4),\n",
       " ('i loathe actors', 4),\n",
       " ('what about military', 4),\n",
       " ('netflix has competition', 4),\n",
       " ('people hate them', 4),\n",
       " ('the kinsey scale', 4),\n",
       " ('a fixed supply', 4),\n",
       " ('where do i', 4),\n",
       " ('words hold power', 4),\n",
       " ('i get it', 4),\n",
       " ('these are boring', 4),\n",
       " ('santa is real', 4),\n",
       " ('there is a', 4),\n",
       " ('we can assume', 4),\n",
       " ('i wont be', 4),\n",
       " ('female and woman', 4),\n",
       " ('the reason is', 4),\n",
       " ('at its core', 4),\n",
       " ('they mean well', 4),\n",
       " ('can you change', 4),\n",
       " ('communication is essential', 4),\n",
       " ('this may sound', 4),\n",
       " ('it seems outrageous', 4),\n",
       " ('this is good', 4),\n",
       " ('women love babies', 4),\n",
       " ('every time i', 4),\n",
       " ('after doing some', 4),\n",
       " ('consider a plant', 4),\n",
       " ('i very much', 4),\n",
       " ('there are other', 4),\n",
       " ('we have this', 4),\n",
       " ('a poor politician', 4),\n",
       " ('context is important', 4),\n",
       " ('this is tangential', 4),\n",
       " ('elisha is jeered', 4),\n",
       " ('reddit \" invented', 4),\n",
       " ('the reason for', 4),\n",
       " ('politics is hard', 4),\n",
       " ('i had said', 4),\n",
       " ('everyone deserves love', 4),\n",
       " ('it is useful', 4),\n",
       " ('it seems as', 4),\n",
       " ('why ban it', 4),\n",
       " ('there is this', 4),\n",
       " ('paternity fraud happens', 4),\n",
       " ('sure it does', 4),\n",
       " ('a lot of', 4),\n",
       " ('vinyl is genuine', 4),\n",
       " ('racial profiling works', 4),\n",
       " ('voting is pointless', 4),\n",
       " ('no haptic feedback', 4),\n",
       " ('upon reaching maturity', 4),\n",
       " ('what about metal', 4),\n",
       " ('synesthesia certainly exists', 4),\n",
       " ('everyone experiences synesthesia', 4),\n",
       " ('it still applies', 4),\n",
       " ('living is hard', 4),\n",
       " ('i think so', 4),\n",
       " ('reddit skews american', 4),\n",
       " ('have you considered', 4),\n",
       " ('children are expensive', 4),\n",
       " ('they are victims', 4),\n",
       " ('i honestly would', 4),\n",
       " ('i have standards', 4),\n",
       " ('which islamic state', 4),\n",
       " ('i am gay', 4),\n",
       " ('people are incorrigible', 4),\n",
       " ('this is understandable', 4),\n",
       " ('an economics article', 4),\n",
       " ('brutality is terrible', 4),\n",
       " ('full disclosure works', 4),\n",
       " ('i was little', 4),\n",
       " ('in most places', 4),\n",
       " ('it seems obvious', 4),\n",
       " ('habit starts somewhere', 4),\n",
       " ('same goes for', 4),\n",
       " ('that would be', 4),\n",
       " ('riots destroy property', 4),\n",
       " ('like being obese', 4),\n",
       " ('the point was', 4),\n",
       " ('function comes first', 4),\n",
       " ('it does matter', 4),\n",
       " ('antisocial is fine', 4),\n",
       " ('they objectively are', 4),\n",
       " ('as for phytoplankton', 4),\n",
       " ('why stop there', 4),\n",
       " ('it is possible', 4),\n",
       " ('that is unfair', 4),\n",
       " ('slang is language', 4),\n",
       " ('in what sense', 4),\n",
       " ('this 10 times', 4),\n",
       " ('in their eyes', 4),\n",
       " ('who protects bitcoin', 4),\n",
       " ('that is hyperbole', 4),\n",
       " ('ethnic grocery stores', 4),\n",
       " ('they might expand', 3),\n",
       " ('it is counterintuitive', 3),\n",
       " ('what does not', 3),\n",
       " ('in the future', 3),\n",
       " ('people make mistakes', 3),\n",
       " ('which is it', 3),\n",
       " ('he was not', 3),\n",
       " ('enough have died', 3),\n",
       " ('fine with refugees', 3),\n",
       " ('without clock stoppage', 3),\n",
       " ('as a chemist', 3),\n",
       " ('do you also', 3),\n",
       " ('intersex people exist', 3),\n",
       " ('think about sexuality', 3),\n",
       " ('if you think', 3),\n",
       " ('at some point', 3),\n",
       " ('you are incorrect', 3),\n",
       " ('it can not', 3),\n",
       " ('i i do', 3),\n",
       " ('since the 1970s', 3),\n",
       " ('cops have authority', 3),\n",
       " ('cars are terrifying', 3),\n",
       " ('no one is', 3),\n",
       " ('in some places', 3),\n",
       " ('the illegal immigrants', 3),\n",
       " ('i agree you', 3),\n",
       " ('this would show', 3),\n",
       " ('look at religion', 3),\n",
       " ('the answer is', 3),\n",
       " ('lebron is overpaid', 3),\n",
       " ('mayo is gross', 3),\n",
       " ('this is important', 3),\n",
       " ('we can safely', 3),\n",
       " ('brain damage here', 3),\n",
       " ('as a man', 3),\n",
       " ('you go hiking', 3),\n",
       " ('as a liberal', 3),\n",
       " ('i never considered', 3),\n",
       " ('he went awol', 3),\n",
       " ('actions have consequences', 3),\n",
       " ('everyone has preferences', 3),\n",
       " ('i could have', 3),\n",
       " ('there are more', 3),\n",
       " ('i totally agree', 3),\n",
       " ('i would have', 3),\n",
       " ('one common practice', 3),\n",
       " ('you are admitting', 3),\n",
       " ('attorneys would balk', 3),\n",
       " ('this is fair', 3),\n",
       " ('the whole point', 3),\n",
       " ('demisexualily is different', 3),\n",
       " ('you seem to', 3),\n",
       " ('logistically implies practicality', 3),\n",
       " ('i am white', 3),\n",
       " ('bad parents exist', 3),\n",
       " ('cats were recruited', 3),\n",
       " ('i like this', 3),\n",
       " ('police are dying', 3),\n",
       " ('the two i', 3),\n",
       " ('humor is subjective', 3),\n",
       " ('it is dumb', 3),\n",
       " ('does that mean', 3),\n",
       " ('this is great', 3),\n",
       " ('it is likely', 3),\n",
       " ('it sounds silly', 3),\n",
       " ('nobody is perfect', 3),\n",
       " ('integration is important', 3),\n",
       " ('we get divorced', 3),\n",
       " ('this is problematic', 3),\n",
       " ('is this true', 3),\n",
       " ('as a scientist', 3),\n",
       " ('i probably should', 3),\n",
       " ('no graven images', 3),\n",
       " ('remember the sabbath', 3),\n",
       " ('your point was', 3),\n",
       " ('the only difference', 3),\n",
       " ('inadequate marriage partners', 3),\n",
       " ('it also seems', 3),\n",
       " ('this is anecdotal', 3),\n",
       " ('you must always', 3),\n",
       " ('why should it', 3),\n",
       " ('is it relevant', 3),\n",
       " ('institutional church protections', 3),\n",
       " ('liberty of conscience', 3),\n",
       " ('true belief plus', 3),\n",
       " ('\" be humble', 3),\n",
       " ('i like you', 3),\n",
       " ('this is one', 3),\n",
       " ('this is different', 3),\n",
       " ('we can all', 3),\n",
       " ('geopolitical situation changes', 3),\n",
       " ('there is no', 3),\n",
       " ('i began to', 3),\n",
       " ('gambling is addictive', 3),\n",
       " ('who is darkseid', 3),\n",
       " ('you convinced me', 3),\n",
       " ('i am atheist', 3),\n",
       " ('what about this', 3),\n",
       " ('not exactly actually', 3),\n",
       " ('it is hard', 3),\n",
       " ('words have meaning', 3),\n",
       " ('it does seem', 3),\n",
       " ('we are not', 3),\n",
       " ('war is inevitable', 3),\n",
       " ('you would agree', 3),\n",
       " ('value is subjective', 3),\n",
       " ('shamans will claim', 3),\n",
       " ('not only that', 3),\n",
       " ('studies have shown', 3),\n",
       " ('i certainly do', 3),\n",
       " ('he tells her', 3),\n",
       " ('encourage healthy lifestyles', 3),\n",
       " ('as a chicagoan', 3),\n",
       " ('i have not', 3),\n",
       " ('a good idea', 3),\n",
       " (\"he ' s\", 3),\n",
       " ('you must recognize', 3),\n",
       " ('a nice computer', 3),\n",
       " ('comcast is evil', 3),\n",
       " ('my argument is', 3),\n",
       " ('my point was', 3),\n",
       " ('people are upset', 3),\n",
       " ('you have you', 3),\n",
       " ('the op was', 3),\n",
       " ('so have men', 3),\n",
       " ('the question is', 3),\n",
       " ('reality is objective', 3),\n",
       " ('you misunderstand it', 3),\n",
       " ('in some cases', 3),\n",
       " ('production is irregular', 3),\n",
       " ('this is bonding', 3),\n",
       " ('quitting was hell', 3),\n",
       " ('did you know', 3),\n",
       " ('it bears consideration', 3),\n",
       " ('you hate yourself', 3),\n",
       " ('we should not', 3),\n",
       " ('it just seems', 3),\n",
       " ('fatalism is similar', 3),\n",
       " ('90 means nothing', 3),\n",
       " ('we already do', 3),\n",
       " ('cold froze faster', 3),\n",
       " ('why must we', 3),\n",
       " ('it is relevant', 3),\n",
       " ('they taste good', 3),\n",
       " ('you can say', 3),\n",
       " ('it just so', 3),\n",
       " ('do you really', 3),\n",
       " ('they all do', 3),\n",
       " ('i definitely agree', 3),\n",
       " ('addiction is unique', 3),\n",
       " ('they probably are', 3),\n",
       " ('kids are smart', 3),\n",
       " ('we actually agree', 3),\n",
       " ('overall or disproportionately', 3),\n",
       " ('do you not', 3),\n",
       " ('why do you', 3),\n",
       " ('i its worth', 3),\n",
       " ('you can ask', 3),\n",
       " ('as for colleges', 3),\n",
       " ('he simply stated', 3),\n",
       " ('this right here', 3),\n",
       " ('the utility ones', 3),\n",
       " ('the car insurance', 3),\n",
       " ('rambling is great', 3),\n",
       " ('why not adoption', 3),\n",
       " ('this is misleading', 3),\n",
       " ('krugman likes shiller', 3),\n",
       " ('this is impossible', 3),\n",
       " ('can i award', 2),\n",
       " ('this convinced me', 2),\n",
       " ('this is subjective', 2),\n",
       " ('the second amendment', 2),\n",
       " ('the latter is', 2),\n",
       " ('something very similar', 2),\n",
       " ('it is selfish', 2),\n",
       " ('not lower quality', 2),\n",
       " ('resources and production', 2),\n",
       " ('you should be', 2),\n",
       " ('nepotism is wrong', 2),\n",
       " ('natural law exists', 2),\n",
       " ('no one does', 2),\n",
       " ('trump was elected', 2),\n",
       " ('times are changing', 2),\n",
       " ('all life matters', 2),\n",
       " ('i read it', 2),\n",
       " ('even with copyright', 2),\n",
       " ('this is transphobic', 2),\n",
       " ('criminals fear batman', 2),\n",
       " ('there was a', 2),\n",
       " ('though its scripted', 2),\n",
       " ('think about your', 2),\n",
       " ('we did it', 2),\n",
       " ('it gets worse', 2),\n",
       " ('i totally disagree', 2),\n",
       " ('it hurts waiters', 2),\n",
       " ('four people died', 2),\n",
       " ('it i am', 2),\n",
       " ('most of the', 2),\n",
       " ('by voting record', 2),\n",
       " ('i do like', 2),\n",
       " ('what i mean', 2),\n",
       " ('a civil war', 2),\n",
       " ('why is this', 2),\n",
       " ('the most i', 2),\n",
       " ('i dont vote', 2),\n",
       " ('stagnation of demand', 2),\n",
       " ('asset price bubbles', 2),\n",
       " ('governing is difficult', 2),\n",
       " ('if the non', 2),\n",
       " ('how about intelligence', 2),\n",
       " ('we shouldnt forget', 2),\n",
       " ('pastafarianism is irrelevant', 2),\n",
       " ('in reading your', 2),\n",
       " ('i am awarding', 2),\n",
       " ('most ideas flourish', 2),\n",
       " ('automation is awesome', 2),\n",
       " ('the djia we', 2),\n",
       " ('that is sexism', 2),\n",
       " ('self - respect', 2),\n",
       " ('mlk impacted millions', 2),\n",
       " ('i was once', 2),\n",
       " ('one might counter', 2),\n",
       " ('do they really', 2),\n",
       " ('i am well', 2),\n",
       " ('you have the', 2),\n",
       " ('it is bad', 2),\n",
       " ('this is cmv', 2),\n",
       " ('some people say', 2),\n",
       " ('as for trump', 2),\n",
       " ('you are mistaken', 2),\n",
       " ('prioritization is simpler', 2),\n",
       " ('they are elevated', 2),\n",
       " ('i would really', 2),\n",
       " ('it really is', 2),\n",
       " ('i am mormon', 2),\n",
       " ('starting a business', 2),\n",
       " ('you will need', 2),\n",
       " ('secondhand smoke sucks', 2),\n",
       " ('you misread me', 2),\n",
       " ('you can counter', 2),\n",
       " ('my definition was', 2),\n",
       " ('i do i', 2),\n",
       " ('the point i', 2),\n",
       " ('automation is coming', 2),\n",
       " ('it looks ridiculous', 2),\n",
       " ('is that true', 2),\n",
       " ('if people are', 2),\n",
       " ('why do i', 2),\n",
       " ('it is argued', 2),\n",
       " ('as with any', 2),\n",
       " ('utility is individual', 2),\n",
       " ('i felt validated', 2),\n",
       " ('poverty breeds violence', 2),\n",
       " ('jobs are boring', 2),\n",
       " ('that would work', 2),\n",
       " ('it does indeed', 2),\n",
       " ('reduce wage laborers', 2),\n",
       " ('not more guns', 2),\n",
       " ('i probably ought', 2),\n",
       " ('the scientific consensus', 2),\n",
       " ('in my personal', 2),\n",
       " ('they are hypocritical', 2),\n",
       " ('nor do i', 2),\n",
       " ('conservatives are aging', 2),\n",
       " ('football wins here', 2),\n",
       " ('look at hollywood', 2),\n",
       " ('you would argue', 2),\n",
       " ('the absolute monarchies', 2),\n",
       " ('the big issue', 2),\n",
       " ('it is rape', 2),\n",
       " ('people cherish firsts', 2),\n",
       " ('maybe they are', 2),\n",
       " ('he does not', 2),\n",
       " ('this is relevant', 2),\n",
       " ('yes it does', 2),\n",
       " ('during this period', 2),\n",
       " ('alcoholism is devastating', 2),\n",
       " ('language is communication', 2),\n",
       " ('dogs are carnivores', 2),\n",
       " ('wp is good', 2),\n",
       " ('you just said', 2),\n",
       " ('never is equal', 2),\n",
       " ('take the burglary', 2),\n",
       " ('i disagree here', 2),\n",
       " ('us general election', 2),\n",
       " ('they enjoy driving', 2),\n",
       " ('the mary sue', 2),\n",
       " ('equestrian is unfair', 2),\n",
       " ('in the ideal', 2),\n",
       " ('ereaders are amazing', 2),\n",
       " ('as for pop', 2),\n",
       " ('in the end', 2),\n",
       " ('there are not', 2),\n",
       " ('do you accept', 2),\n",
       " ('i no longer', 2),\n",
       " ('as for detroit', 2),\n",
       " ('parallel parking especially', 2),\n",
       " ('i hated it', 2),\n",
       " ('you should care', 2),\n",
       " ('colour and taste', 2),\n",
       " ('person a it', 2),\n",
       " ('it is different', 2),\n",
       " ('gays are icky', 2),\n",
       " ('nearly all animals', 2),\n",
       " ('as a vegan', 2),\n",
       " ('in the context', 2),\n",
       " ('this is tough', 2),\n",
       " ('you lose them', 2),\n",
       " ('fuck the media', 2),\n",
       " ('as for naming', 2),\n",
       " ('tomatoes are healthy', 2),\n",
       " ('only it is', 2),\n",
       " ('the premise is', 2),\n",
       " ('i never realized', 2),\n",
       " ('poor social skills', 2),\n",
       " ('faith is trickier', 2),\n",
       " ('both are good', 2),\n",
       " ('make aggregation illegal', 2),\n",
       " ('these pistols are', 2),\n",
       " ('i do let', 2),\n",
       " ('centrism is popular', 2),\n",
       " ('meritocracy is unfair', 2),\n",
       " ('this paradigm only', 2),\n",
       " ('it is important', 2),\n",
       " ('my argument still', 2),\n",
       " ('8 - 9', 2),\n",
       " ('7 - average', 2),\n",
       " ('these are great', 2),\n",
       " ('benji was awesome', 2),\n",
       " ('your responses are', 2),\n",
       " ('have you noticed', 2),\n",
       " ('statistics are important', 2),\n",
       " ('the principal example', 2),\n",
       " ('i can help', 2),\n",
       " ('it is a', 2),\n",
       " ('i always do', 2),\n",
       " ('they help others', 2),\n",
       " ('within party primaries', 2),\n",
       " ('the big difference', 2),\n",
       " ('the libertarian party', 2),\n",
       " ('in the nfl', 2),\n",
       " ('trademarks are important', 2),\n",
       " ('they have to', 2),\n",
       " ('the thing you', 2),\n",
       " ('the job market', 2),\n",
       " ('morality informs legality', 2),\n",
       " ('this is legal', 2),\n",
       " ('there are fewer', 2),\n",
       " ('black was interesting', 2),\n",
       " ('it also astonishes', 2),\n",
       " ('people have this', 2),\n",
       " ('i fully acknowledge', 2),\n",
       " ('chips have charm', 2),\n",
       " ('are they though', 2),\n",
       " ('you sin too', 2),\n",
       " ('you need to', 2),\n",
       " ('even with this', 2),\n",
       " ('nothing is absolute', 2),\n",
       " ('the basic premise', 2),\n",
       " ('fat acceptance you', 2),\n",
       " ('yes they would', 2),\n",
       " ('i could it', 2),\n",
       " ('music is different', 2),\n",
       " ('it detracts from', 2),\n",
       " ('only one body', 2),\n",
       " ('food is energy', 2),\n",
       " ('my main point', 2),\n",
       " ('right to healthcare', 2),\n",
       " ('nothing is original', 2),\n",
       " ('this is laughable', 2),\n",
       " ('it made sense', 2),\n",
       " ('the transition period', 2),\n",
       " ('what makes you', 2),\n",
       " ('people eat meat', 2),\n",
       " ('i often jaywalk', 2),\n",
       " ('it is appropriate', 2),\n",
       " ('this 2016 election', 2),\n",
       " ('as for calculus', 2),\n",
       " ('aside from criminality', 2),\n",
       " ('i feel helpless', 2),\n",
       " ('general hidden features', 2),\n",
       " ('this is my', 2),\n",
       " ('what is sexisim', 2),\n",
       " ('asians do better', 2),\n",
       " ('not vaccinating kids', 2),\n",
       " ('this is astounding', 2),\n",
       " ('there was trump', 2),\n",
       " ('make it so', 2),\n",
       " ('take global poverty', 2),\n",
       " ('it is difficult', 2),\n",
       " ('voting should be', 2),\n",
       " ('look at evolution', 2),\n",
       " ('what about the', 2),\n",
       " ('we have universities', 2),\n",
       " ('there could be', 2),\n",
       " ('you are stating', 2),\n",
       " ('they literally cant', 2),\n",
       " ('profits reflect risk', 2),\n",
       " ('i could not', 2),\n",
       " ('preferences are preferences', 2),\n",
       " ('what would happen', 2),\n",
       " ('gay conversion therapy', 2),\n",
       " ('we can estimate', 2),\n",
       " ('my primary issue', 2),\n",
       " ('it promotes stds', 2),\n",
       " ('does the impossible', 2),\n",
       " ('we do not', 2),\n",
       " ('i my understanding', 2),\n",
       " ('this should work', 2),\n",
       " ('as a male', 2),\n",
       " ('i wont lie', 2),\n",
       " ('this should change', 2),\n",
       " ('it is justifiable', 2),\n",
       " ('this is reddit', 2),\n",
       " ('some will argue', 2),\n",
       " ('the whole reason', 2),\n",
       " ('your assumption is', 2),\n",
       " ('she can fight', 2),\n",
       " ('she can fly', 2),\n",
       " ('i love weed', 2),\n",
       " ('america is two', 2),\n",
       " ('look at isil', 2),\n",
       " ('investing requires risk', 2),\n",
       " ('murder is immoral', 2),\n",
       " ('increasing romantic success', 2),\n",
       " ('you are not', 2),\n",
       " ('the death penalty', 2),\n",
       " ('the entire it', 2),\n",
       " ('the so wins', 2),\n",
       " ('you must show', 2),\n",
       " ('we need to', 2),\n",
       " ('do are you', 2),\n",
       " ('concerning unit 731', 2),\n",
       " ('across the board', 2),\n",
       " ('you deserve a', 2),\n",
       " ('i looked around', 2),\n",
       " ('college is easy', 2),\n",
       " ('i would like', 2),\n",
       " ('im tone deaf', 2),\n",
       " ('snowden is embellishing', 2),\n",
       " ('the delta went', 2),\n",
       " ('sea level rise', 2),\n",
       " ('severe weather events', 2),\n",
       " ('diamonds are hard', 2),\n",
       " ('around the world', 2),\n",
       " ('i do so', 2),\n",
       " ('quite the opposite', 2),\n",
       " ('could you explain', 2),\n",
       " ('want to fly', 2),\n",
       " ('i am bisexual', 2),\n",
       " ('i was well', 2),\n",
       " ('when used topically', 2),\n",
       " ('the only e', 2),\n",
       " ('it nothing is', 2),\n",
       " ('i i have', 2),\n",
       " ('something terrible happens', 2),\n",
       " ('so does government', 2),\n",
       " ('like everything else', 2),\n",
       " ('bitcoin is global', 2),\n",
       " ('bitcoin is decentralized', 2),\n",
       " ('democracy is necessary', 2),\n",
       " ('one can certainly', 2),\n",
       " ('i used to', 2),\n",
       " ('for hockey specifically', 2),\n",
       " ('at this time', 2),\n",
       " ('riding too fast', 2),\n",
       " ('i am nonreligious', 2),\n",
       " ('i like cars', 2),\n",
       " ('empathy , solidarity', 2),\n",
       " ('famous quotes say', 2),\n",
       " ('which is exactly', 2),\n",
       " ('i guess so', 2),\n",
       " ('another option is', 2),\n",
       " ('the research shows', 2),\n",
       " ('by opinion only', 2),\n",
       " ('most fat people', 2),\n",
       " ('i am tired', 2),\n",
       " ('in real world', 2),\n",
       " ('xml is extensible', 2),\n",
       " ('this is unreasonable', 2),\n",
       " ('businesses are businesses', 2),\n",
       " ('r3m0t has explained', 2),\n",
       " ('at their basis', 2),\n",
       " ('look at rust', 2),\n",
       " ('you might be', 2),\n",
       " ('i online date', 2),\n",
       " ('to achieve equality', 2),\n",
       " ('the federal government', 2),\n",
       " ('this passage says', 2),\n",
       " ('we need contrast', 2),\n",
       " ('are you circumcised', 2),\n",
       " ('the reason i', 2),\n",
       " ('about my atheism', 2),\n",
       " ('that already happens', 2),\n",
       " ('especially with music', 2),\n",
       " ('we have a', 2),\n",
       " ('boehner recognized this', 2),\n",
       " ('i pity boehner', 2),\n",
       " ('i love teaching', 2),\n",
       " ('breast is best', 2),\n",
       " ('why you should', 2),\n",
       " ('by price discrimination', 2),\n",
       " ('religion promotes helplessness', 2),\n",
       " ('i should probably', 2),\n",
       " ('you always stand', 2),\n",
       " ('speech is powerful', 2),\n",
       " ('as time progresses', 2),\n",
       " ('the threshold itself', 2),\n",
       " ('i undersell myself', 2),\n",
       " ('if i understand', 2),\n",
       " ('americans do not', 2),\n",
       " ('hitler was evil', 2),\n",
       " ('the problem with', 2),\n",
       " ('terrorists are criminals', 2),\n",
       " ('i would still', 2),\n",
       " ('you have friends', 2),\n",
       " ('let he who', 2),\n",
       " ('no inherent value', 2),\n",
       " ('i hate women', 2),\n",
       " ('most utilitarians argue', 2),\n",
       " ('this has consequences', 2),\n",
       " ('people need healthcare', 2),\n",
       " ('cost to taxpayer', 2),\n",
       " ('peta kills animals', 2),\n",
       " ('take a murder', 2),\n",
       " ('teenagers are naive', 2),\n",
       " ('the us constitution', 2),\n",
       " ('reddit is brogressive', 2),\n",
       " ('many might argue', 2),\n",
       " ('i prefer over', 2),\n",
       " ('these things matter', 2),\n",
       " ('in both cases', 2),\n",
       " ('i hate chemistry', 2),\n",
       " ('voter turnout increases', 2),\n",
       " ('this possibility exists', 2),\n",
       " ('a perfect crust', 2),\n",
       " ('a flavorful sauce', 2),\n",
       " ('what is fascism', 2),\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the clean post data and prepare paragraph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_posts = [[], []]\n",
    "for i, key in enumerate(['pos', 'neg']):\n",
    "    with open('./../preprocess/cmv_raw/parsing/clean_{}_single'.format(key)) as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            clean_posts[i].append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [{}, {}]\n",
    "for side in range(2):\n",
    "    for clean_post in clean_posts[side]:\n",
    "        topic_id, post_id = [int(_) for _ in clean_post['uid'].split('_')]\n",
    "\n",
    "        # if there are post longer than 480\n",
    "        if(topic_id in check):\n",
    "            continue\n",
    "\n",
    "        if(topic_id not in posts[side]):\n",
    "            posts[side][topic_id] = {\n",
    "                'topic':clean_post['topic'],\n",
    "                'content':[]\n",
    "            }\n",
    "        while(len(posts[side][topic_id]['content'])<=post_id):\n",
    "            posts[side][topic_id]['content'].append(None)\n",
    "            \n",
    "        posts[side][topic_id]['content'][post_id] = {\n",
    "            'bio':[None for _ in clean_post['context']],\n",
    "            'context':clean_post['context'],\n",
    "            'type':[None for _ in clean_post['context']]\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for side in range(2):\n",
    "    for index, sent, bio, dtype in zip(recover[side]['index'], recover[side]['sent'], recover[side]['bio'], recover[side]['type']):\n",
    "        topic_id, post_id, para_id = [ int(_) for _ in index_mapping[side][index].split('_')]\n",
    "        \n",
    "        if(topic_id not in posts[side]):\n",
    "            continue\n",
    "            \n",
    "        posts[side][topic_id]['content'][post_id]['context'][para_id] = sent\n",
    "        posts[side][topic_id]['content'][post_id]['bio'][para_id] = ' '.join(bio)\n",
    "        posts[side][topic_id]['content'][post_id]['type'][para_id] = dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for side in range(2):\n",
    "    topic_ids = list(posts[side].keys())\n",
    "    \n",
    "    for topic_id in topic_ids:\n",
    "        dtype = []\n",
    "        try:\n",
    "            for post_id in range(len( posts[side][topic_id]['content'] )):\n",
    "                dtype = []\n",
    "                for _ in posts[side][topic_id]['content'][post_id]['type']:\n",
    "                    dtype.extend(_)\n",
    "                posts[side][topic_id]['content'][post_id]['type'] = dtype\n",
    "        except TypeError:\n",
    "            for side in range(2):\n",
    "                if(topic_id in posts[side]):\n",
    "                    del posts[side][topic_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bio': ['O O O O O B I I I I I I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I O',\n",
       "  'O O O O O O B I I I I I I O O O O O O O O O O O O O',\n",
       "  'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I I I I I I I I O O B I I I I I I I I I I I I I I I I I I I O O O O O B I I I I I I I O O B I I I I I I I I I I I I I I I I I I I I O O O O O O O O O O O O O O O O O O O O'],\n",
       " 'context': [\"i have to say that i am very disappointed with the current state of political discourse in today ' s society . both in mass media and the internet , political discussion seems to be ruled by angry extremists who think that the other side is evil and shout down , insult and in some case censor anyone who does not think so . many times over i ' ve dealt with those types of people ( both from the left and the right ) only to find out that reason and logic rarely , if ever work on them . their extreme views also focus a lot of outrage ( sometimes from other extremists ) , often derailing the discussion from the original topic .\",\n",
       "  'so i have a question : do you guys this can be fixed ? or is this just the gift in practise ? ( link )',\n",
       "  \"> hello , users of cmv ! this is a footnote from your moderators . we ' d just like to remind you of a couple of things . firstly , please remember to read through our rules ( link ) . if you see a comment that has broken one , it is more effective to report it than downvote it . speaking of which , downvotes do ' t change views ( link ) ! if you are thinking about submitting a cmv yourself , please have a look through our popular topics wiki ( link ) first . any questions or concerns ? feel free to message us ( link ) . happy cmving !\"],\n",
       " 'type': ['C', 'P', 'P', 'P', 'C', 'P', 'P', 'P', 'P']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[0][0]['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process link \n",
    "EOS_tokens_list = [\".\", \"!\", \"?\", \"</ac>\", \"<para>\"]\n",
    "\n",
    "def find_shell(index, last, context, adu_index):\n",
    "    if(index==0):\n",
    "        return (0, 0)\n",
    "    for i in range(index, last-1, -1):\n",
    "        if(context[i] in EOS_tokens_list):\n",
    "            break\n",
    "    return (adu_index, i , index-1)\n",
    "\n",
    "def prepare(data, elmo_preprocess):\n",
    "    mask = []\n",
    "    shell_span, span, elmo_index = [], [], []\n",
    "    adu_index = 0\n",
    "    adu_label = []\n",
    "    \n",
    "    topic_elmo_index = len(elmo_preprocess)\n",
    "    elmo_preprocess.append('<topic> '+data['topic']+' </topic>')\n",
    "    elmo_preprocess[-1] = ' '.join(elmo_preprocess[-1].split())\n",
    "    \n",
    "    ac_position_info = []\n",
    "    \n",
    "    for post_pos, post in enumerate(data['content']):\n",
    "        for bio, context in zip(post['bio'], post['context']):\n",
    "            elmo_index.append(len(elmo_preprocess))\n",
    "\n",
    "            elmo_preprocess.append(['<para>'])\n",
    "            bio, context = bio.split(), context.split()\n",
    "\n",
    "            last = None\n",
    "            for l, word in zip(bio, context):\n",
    "                if((l=='O' or l=='B') and last=='I'):\n",
    "                    elmo_preprocess[-1].append('</ac>')\n",
    "                if(l=='B'):\n",
    "                    elmo_preprocess[-1].append('<ac>')\n",
    "                elmo_preprocess[-1].append(word)\n",
    "\n",
    "                last = l\n",
    "\n",
    "            elmo_preprocess[-1].append('</para>')\n",
    "\n",
    "            last = -1\n",
    "            for index in range(len(elmo_preprocess[-1])):\n",
    "                if(elmo_preprocess[-1][index] == '<ac>'):\n",
    "                    span.append([adu_index, index, 0])\n",
    "                    shell_span.append(find_shell(index, last, elmo_preprocess[-1], adu_index))\n",
    "\n",
    "                elif(elmo_preprocess[-1][index] == '</ac>'):\n",
    "                    assert(span[-1][-1]==0), \"last should be zero\"\n",
    "                    span[-1][-1] = index\n",
    "                    last = index\n",
    "            elmo_preprocess[-1] = ' '.join(elmo_preprocess[-1])\n",
    "            # update parameter\n",
    "            adu_index += 1\n",
    "\n",
    "        # build mask\n",
    "        dtype = post['type']\n",
    "        prev_len, now_len = len(adu_label), len(dtype)\n",
    "        for adu_pos, _ in enumerate(dtype):\n",
    "            if(_ == 'P'):\n",
    "                # constrain search space to this reply\n",
    "                mask.append([0]*prev_len + [1]*now_len)\n",
    "\n",
    "            elif(_ == 'C'):\n",
    "                # constrain search space to all\n",
    "                mask.append([1]*(prev_len + now_len))\n",
    "\n",
    "            ac_position_info.append([adu_pos, post_pos])\n",
    "\n",
    "        adu_label.extend( dtype )\n",
    "\n",
    "        \n",
    "        \n",
    "    return {\n",
    "        'topic_index':topic_elmo_index, \n",
    "        'elmo_index':elmo_index,\n",
    "        'shell_span':shell_span, \n",
    "        'span':span, \n",
    "        'mask':mask, \n",
    "        'adu_label':adu_label,\n",
    "        'ac_position_info':ac_position_info\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "last should be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-23c959e776d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mside\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtopic_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-59ec87ab16b2>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(data, elmo_preprocess)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melmo_preprocess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'</ac>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last should be zero\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: last should be zero"
     ]
    }
   ],
   "source": [
    "prepare_data = [[], []]\n",
    "elmo_preprocess = []\n",
    "\n",
    "for side in range(2):\n",
    "    for topic_id in posts[side]:\n",
    "        temp = prepare(posts[side][topic_id], elmo_preprocess)\n",
    "        temp['uid'] = '{}_{}'.format(side, topic_id)\n",
    "        \n",
    "        prepare_data[side].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['topic_index', 'elmo_index', 'shell_span', 'span', 'mask', 'adu_label', 'ac_position_info', 'uid'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "54\n",
      "68\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "for side in range(2):\n",
    "    for _ in prepare_data[side]:\n",
    "        m = max(m, len(_['span']))\n",
    "        if(m == len(_['span'])):\n",
    "            print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<para> <ac> what i think we should do is go after these people </ac> . <ac> if instead of a giant wall and an insane increase in a task force , it would be a lot cheaper to have a regulative authority that regularly audits and investigates companies that engage in this practice </ac> . and <ac> companies that are found engaging in it should face severe punishment </ac> ... .i 'm talking massive fines for first offense and revoking of business licenses in other offenses , potentially increasing to the point of confiscating the business and property </ac> . </para>\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(elmo_preprocess[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bio': ['O O O B I I I I I I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I O B I I I I I O',\n",
       "   'B I I I I I I I I I I I I I O B I I I I I I I I I I I I I O B I I I I I I I I I O O B I I I I I I I I I O O O B I I I I I I I I I I I I I I I I I I I I O O O O B I I I I I I I I I I I I O',\n",
       "   'B I I I I I I I I I I I I I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I O',\n",
       "   'B I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I O O B I I I I I I I I I I O O I I I I I I I I I I I I I I I I I I I I I I I I I I I O',\n",
       "   'B I I I I I I I I I I I I I I I O O B I I I I I I I I I I I I I I I I I I I O',\n",
       "   'O O O O O B I I I I I I I O O O O O O O B I I I I I I I I I I I O O O O',\n",
       "   'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I O O O B I I I I I I I I I I I I O O O O O O B I I I I I I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I O O O O O O O O B I I I I I I I I B I I I I I I I I I I I I I I I I I I I I I I I I I I I I O',\n",
       "   'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'],\n",
       "  'context': ['so clearly , we are living in a time where we feel justified to hate on \" illegals \" . the solution that the president-elect has been talking about for years is a giant wall on the us southern border . i see this solution as such :',\n",
       "   \"i have a giant block of cheese sitting in the middle of my house . mice will not stop getting into my house and eating this block of cheese ( i do't think mice are really into cheese like this , but i can't think of a better analogy at the moment ) . so my idea is to leave the block of cheese and try catching the mice and releasing them back outside my house . of course , they know the cheese is there and they keep coming for the cheese .\",\n",
       "   'the problem with undocumented workers coming into the country to take jobs is that there is someone offering these jobs to undocumented workers . construction crews , agriculture , etc. , are all industries where the leaders can save a whole lot of money by having undocumented workers , pay them salaries below minimum wage , offer no benefits , and threaten to have them deported .',\n",
       "   \"what i think we should do is go after these people . if instead of a giant wall and an insane increase in a task force , it would be a lot cheaper to have a regulative authority that regularly audits and investigates companies that engage in this practice . and companies that are found engaging in it should face severe punishment ... .i 'm talking massive fines for first offense and revoking of business licenses in other offenses , potentially increasing to the point of confiscating the business and property .\",\n",
       "   'i assume that there is already a bit of a penalty in place for these employers , but the risk of getting caught must still be cheaper than the cost of only hiring american workers at decent wages .',\n",
       "   \"edit : okay everyone , i object to using the word illegal to describe an entire group of people . it 's insensitive , offensive , and in the context , racist . ( link )\",\n",
       "   \"edit 2 : let me clarify my personal views . i think this country needs more immigration , not less . i think we need open borders and that we 're moving towards globalization and overall , we need to move away from the idea of american superiority . i truly do't believe that illegal immigration is a problem severe enough to warrant building a massive wall , though i do concede that it may be easier to try to keep people out than to try to regulate business . my main issue is the republican talking point , and one of the cornerstones of the president-elect 's campaign that blames undocumented workers for taking american jobs and making the country less safe . and i do believe that even though it 's not an easy thing to do , we should be working more to fight the people that wish to exploit desperate people than the people willing to do anything to improve the lives of their family .\",\n",
       "   \"> hello , users of cmv ! this is a footnote from your moderators . we 'd just like to remind you of a couple of things . firstly , please remember to read through our rules ( link ) . if you see a comment that has broken one , it is more effective to report it than downvote it . speaking of which , downvotes do't change views ( link ) ! if you are thinking about submitting a cmv yourself , please have a look through our popular topics wiki ( link ) first . any questions or concerns ? feel free to message us ( link ) . happy cmving !\"],\n",
       "  'type': ['C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'P',\n",
       "   'P',\n",
       "   'P',\n",
       "   'P',\n",
       "   'C',\n",
       "   'P',\n",
       "   'C',\n",
       "   'P',\n",
       "   'C',\n",
       "   'P',\n",
       "   'P',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C']},\n",
       " {'bio': ['B I I B I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I I I I I O B I I I I I I I I I I I I I I I I I I I I I I I I O'],\n",
       "  'context': ['the problem is many illegals do\\'t work regular jobs . they work in fields and are paid cash , or they \\'re nannys , or the guy that came around asking to rake our leaves for $ 20 . many of them work \" gig \" type jobs where it \\'s unreasonable to expect people to have the resources to verify their immigration status .'],\n",
       "  'type': ['C', 'C', 'P', 'P']},\n",
       " {'bio': ['B I I I I I I I I I I O'],\n",
       "  'context': ['i disqualify this due to using the word \" illegals \" .'],\n",
       "  'type': ['C']},\n",
       " {'bio': ['B I I I I I I I I I B I I I I I I I I I I I I I I I I I I I'],\n",
       "  'context': ['that \\'s a fickle reason to dismiss a point . if you find/replace \" illegals \" with \" people in the country illegally \" do you find it convincing ?'],\n",
       "  'type': ['C', 'P']},\n",
       " {'bio': ['O O O O O O O B I I I I I I I I I O'],\n",
       "  'context': [\"based on op 's response here , obviously op is not looking to get his/her mind changed .\"],\n",
       "  'type': ['C']},\n",
       " {'bio': ['O O O O O O O O O O O O O O O O',\n",
       "   'B I I I I I I I I I I I I I I I B B I I I I I I I I I I I I I I I B I I O O O O O O O'],\n",
       "  'context': ['interesting you say that since further in the thread , i already awarded a delta .',\n",
       "   'the term \" illegals \" being used to define a group of people is offensive and since it is used ( definitely in this context ) to describe a particular racial group , it \\'s racist . ( link ) language matters .'],\n",
       "  'type': ['C', 'P', 'P', 'P']},\n",
       " {'bio': ['O O O O O O O O O O O O O O O O O O O O O O'],\n",
       "  'context': ['op maybe you can add in the description how you feel about the word , to avoid more instances popping up ?'],\n",
       "  'type': []},\n",
       " {'bio': ['O O O O O O O O'],\n",
       "  'context': ['and i just did . : - )'],\n",
       "  'type': []}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[side][topic_id]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9282\n",
      "[CLS]  - this reasoning was very convincing , it always occurred to me that penetrating the box was a default offensive strategy and that therefore suspend ##ing offs ##ides in the box would not considerably change the tactics used on ##field . this perspective has helped change my mind . [SEP]\n",
      "\n",
      "1 2 [CLS]\n",
      "0 2 \n",
      "0 2 -\n",
      "0 2 this\n",
      "0 2 reasoning\n",
      "0 2 was\n",
      "0 2 very\n",
      "0 2 convincing\n",
      "0 2 ,\n",
      "0 2 it\n",
      "0 2 always\n",
      "0 2 occurred\n",
      "0 2 to\n",
      "0 2 me\n",
      "0 2 that\n",
      "0 0 penetrating\n",
      "0 1 the\n",
      "0 1 box\n",
      "0 1 was\n",
      "0 1 a\n",
      "0 1 default\n",
      "0 1 offensive\n",
      "0 1 strategy\n",
      "0 2 and\n",
      "0 2 that\n",
      "0 2 therefore\n",
      "0 2 suspend\n",
      "1 0 ##ing\n",
      "0 1 offs\n",
      "1 1 ##ides\n",
      "0 1 in\n",
      "0 1 the\n",
      "0 1 box\n",
      "0 1 would\n",
      "0 1 not\n",
      "0 1 considerably\n",
      "0 1 change\n",
      "0 1 the\n",
      "0 1 tactics\n",
      "0 1 used\n",
      "0 1 on\n",
      "1 2 ##field\n",
      "0 2 .\n",
      "0 2 this\n",
      "0 2 perspective\n",
      "0 2 has\n",
      "0 2 helped\n",
      "0 2 change\n",
      "0 2 my\n",
      "0 2 mind\n",
      "0 2 .\n",
      "2 2 [SEP]\n"
     ]
    }
   ],
   "source": [
    "side, index = 0, 9282\n",
    "\n",
    "c = index_mapping[side][index]\n",
    "for index, _ in enumerate(index_mapping[side]):\n",
    "    if(_ ==c):\n",
    "        print(index)\n",
    "        break\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(pred[side]['id'][index].tolist()[:len(pred[side]['bio'][index])])))\n",
    "print()\n",
    "for word, bio, r in zip(tokenizer.convert_ids_to_tokens(pred[side]['id'][index].tolist()), pred[side]['bio'][index], pred[side]['recover'][index].tolist()):\n",
    "    print(r,bio,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor bio, word in zip(posts[side][topic_id]['content'][0]['bio'][3].split(), posts[side][topic_id]['content'][0]['context'][3].split()):\\n    print(bio, word)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for bio, word in zip(posts[side][topic_id]['content'][0]['bio'][3].split(), posts[side][topic_id]['content'][0]['context'][3].split()):\n",
    "    print(bio, word)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9282\n",
      "0 10078\n",
      "0 10233\n",
      "0 20693\n",
      "0 20695\n",
      "0 21906\n",
      "0 24220\n",
      "0 24464\n",
      "0 25223\n",
      "0 31012\n",
      "0 31447\n",
      "0 32848\n",
      "0 33023\n",
      "0 33333\n",
      "0 33350\n",
      "0 37964\n",
      "0 38032\n",
      "0 38320\n",
      "0 39184\n",
      "0 39603\n",
      "0 39794\n",
      "0 44531\n",
      "0 45445\n",
      "0 47456\n",
      "0 47668\n",
      "0 48072\n",
      "0 49641\n",
      "0 49653\n",
      "0 50368\n",
      "0 50777\n",
      "0 51517\n",
      "0 54778\n",
      "0 57569\n",
      "0 58099\n",
      "0 60946\n",
      "0 61893\n",
      "0 62351\n",
      "0 64087\n",
      "0 64319\n",
      "0 65831\n",
      "0 65974\n",
      "0 69721\n",
      "0 71947\n",
      "0 72166\n",
      "0 73694\n",
      "0 73746\n",
      "0 74994\n",
      "0 74995\n",
      "0 75420\n",
      "0 77238\n",
      "0 78650\n",
      "0 78751\n",
      "0 79430\n",
      "0 84061\n",
      "0 84892\n",
      "0 86953\n",
      "0 87409\n",
      "0 87750\n",
      "0 88068\n",
      "0 88385\n",
      "0 88469\n",
      "0 88707\n",
      "0 88875\n",
      "0 96909\n",
      "0 100934\n",
      "0 103899\n",
      "0 104280\n",
      "0 104461\n",
      "0 106998\n",
      "0 107009\n",
      "0 107595\n",
      "0 109584\n",
      "0 111787\n",
      "0 112419\n",
      "0 113904\n",
      "0 119493\n",
      "0 119889\n",
      "0 120152\n",
      "0 120409\n",
      "0 120839\n",
      "0 121063\n",
      "0 121323\n",
      "0 121546\n",
      "0 125741\n",
      "0 125884\n",
      "0 126286\n",
      "0 126509\n",
      "0 127708\n",
      "0 128001\n",
      "0 128275\n",
      "0 128637\n",
      "0 128926\n",
      "0 129144\n",
      "0 131392\n",
      "0 133750\n",
      "0 134100\n",
      "0 134134\n",
      "0 134361\n",
      "0 134385\n",
      "0 134791\n",
      "0 139000\n",
      "0 139196\n",
      "0 146266\n",
      "0 147043\n",
      "0 154240\n",
      "0 156811\n",
      "0 157659\n",
      "0 158246\n",
      "0 158745\n",
      "0 159943\n",
      "0 160357\n",
      "0 160840\n",
      "0 161186\n",
      "0 161753\n",
      "0 161869\n",
      "0 161967\n",
      "0 163615\n",
      "0 167686\n",
      "0 167761\n",
      "0 172121\n",
      "0 172717\n",
      "0 174731\n",
      "0 178772\n",
      "0 179444\n",
      "0 180579\n",
      "0 182914\n",
      "0 183005\n",
      "0 183424\n",
      "0 190927\n",
      "0 191690\n",
      "0 192829\n",
      "0 195052\n",
      "0 203672\n",
      "0 210977\n",
      "0 211396\n",
      "0 213013\n",
      "0 213298\n",
      "0 213714\n",
      "0 214011\n",
      "0 214149\n",
      "0 214296\n",
      "0 214682\n",
      "0 214883\n",
      "0 215229\n",
      "0 217401\n",
      "0 221269\n",
      "0 221458\n",
      "0 225296\n",
      "0 225558\n",
      "0 225756\n",
      "0 226055\n",
      "0 226258\n",
      "0 226564\n",
      "0 226653\n",
      "0 227682\n",
      "0 232811\n",
      "0 233332\n",
      "0 235106\n",
      "0 235434\n",
      "0 235865\n",
      "0 238286\n",
      "0 241577\n",
      "0 242548\n",
      "0 243277\n",
      "0 243290\n",
      "0 248686\n",
      "0 258914\n",
      "0 262445\n",
      "0 264037\n",
      "0 267355\n",
      "0 271977\n",
      "0 272942\n",
      "0 273368\n",
      "0 275767\n",
      "0 277488\n",
      "0 277760\n",
      "0 277784\n",
      "0 280581\n",
      "0 283411\n",
      "0 289386\n",
      "0 292174\n",
      "0 292709\n",
      "0 296035\n",
      "0 296088\n",
      "0 296241\n",
      "0 296370\n",
      "0 296399\n",
      "0 296529\n",
      "0 296574\n",
      "0 296766\n",
      "0 296792\n",
      "0 297108\n",
      "0 300804\n",
      "0 302486\n",
      "0 302606\n",
      "0 302979\n",
      "0 304039\n",
      "0 308926\n",
      "0 310393\n",
      "0 312439\n",
      "0 318464\n",
      "1 88\n",
      "1 2965\n",
      "1 4385\n",
      "1 8559\n",
      "1 9089\n",
      "1 11083\n",
      "1 11221\n",
      "1 12534\n",
      "1 18243\n",
      "1 22997\n",
      "1 24414\n",
      "1 25521\n",
      "1 25885\n",
      "1 26035\n",
      "1 26681\n",
      "1 33705\n",
      "1 34048\n",
      "1 35576\n",
      "1 40551\n",
      "1 41054\n",
      "1 41808\n",
      "1 42325\n",
      "1 47554\n",
      "1 50582\n",
      "1 50632\n",
      "1 50924\n",
      "1 51267\n",
      "1 51334\n",
      "1 52389\n",
      "1 53090\n",
      "1 53910\n",
      "1 53938\n",
      "1 54495\n",
      "1 54960\n",
      "1 60748\n",
      "1 62111\n",
      "1 62690\n",
      "1 65092\n",
      "1 65821\n",
      "1 69344\n",
      "1 71232\n",
      "1 71768\n",
      "1 72308\n",
      "1 75878\n",
      "1 76167\n",
      "1 77118\n",
      "1 77265\n",
      "1 78648\n",
      "1 79170\n",
      "1 80159\n",
      "1 80160\n",
      "1 80230\n",
      "1 80700\n",
      "1 84160\n",
      "1 86895\n",
      "1 87653\n",
      "1 89613\n",
      "1 90924\n",
      "1 92536\n",
      "1 93012\n",
      "1 93458\n",
      "1 93884\n",
      "1 94167\n",
      "1 94272\n",
      "1 94603\n",
      "1 94659\n",
      "1 95085\n",
      "1 96536\n",
      "1 100591\n",
      "1 100635\n",
      "1 101324\n",
      "1 103588\n",
      "1 103944\n",
      "1 104586\n",
      "1 104759\n",
      "1 105652\n",
      "1 111007\n",
      "1 111469\n",
      "1 112006\n",
      "1 112858\n",
      "1 117397\n",
      "1 117426\n",
      "1 119167\n",
      "1 119866\n",
      "1 127569\n",
      "1 127950\n",
      "1 128356\n",
      "1 128824\n",
      "1 129037\n",
      "1 129229\n",
      "1 129474\n",
      "1 129756\n",
      "1 129809\n",
      "1 134703\n",
      "1 134848\n",
      "1 135192\n",
      "1 136145\n",
      "1 136619\n",
      "1 136737\n",
      "1 137073\n",
      "1 137388\n",
      "1 137674\n",
      "1 139337\n",
      "1 139600\n",
      "1 145254\n",
      "1 145740\n",
      "1 145981\n",
      "1 146165\n",
      "1 148295\n",
      "1 148671\n",
      "1 150013\n",
      "1 152567\n",
      "1 154346\n",
      "1 156631\n",
      "1 157128\n",
      "1 158059\n",
      "1 159097\n",
      "1 169080\n",
      "1 169506\n",
      "1 170968\n",
      "1 171526\n",
      "1 172219\n",
      "1 172806\n",
      "1 173493\n",
      "1 176353\n",
      "1 179104\n",
      "1 179214\n",
      "1 180363\n",
      "1 180682\n",
      "1 183268\n",
      "1 184310\n",
      "1 187265\n",
      "1 187504\n",
      "1 190791\n",
      "1 192030\n",
      "1 194956\n",
      "1 194958\n",
      "1 196084\n",
      "1 199157\n",
      "1 201849\n",
      "1 204633\n",
      "1 205226\n",
      "1 205316\n",
      "1 205805\n",
      "1 206061\n",
      "1 206733\n",
      "1 211412\n",
      "1 211778\n",
      "1 217904\n",
      "1 219630\n",
      "1 219755\n",
      "1 221754\n",
      "1 226122\n",
      "1 228527\n",
      "1 228790\n",
      "1 229172\n",
      "1 229426\n",
      "1 229620\n",
      "1 229627\n",
      "1 229748\n",
      "1 230129\n",
      "1 230360\n",
      "1 230808\n",
      "1 230865\n",
      "1 233293\n",
      "1 237147\n",
      "1 237474\n",
      "1 242253\n",
      "1 242662\n",
      "1 242900\n",
      "1 243092\n",
      "1 243778\n",
      "1 244282\n",
      "1 244775\n",
      "1 252703\n",
      "1 253075\n",
      "1 259389\n",
      "1 259644\n",
      "1 259772\n",
      "1 260702\n",
      "1 266800\n",
      "1 267151\n",
      "1 267295\n",
      "1 267568\n",
      "1 269360\n",
      "1 269360\n",
      "1 269480\n",
      "1 270214\n",
      "1 274032\n",
      "1 278643\n",
      "1 279007\n",
      "1 280321\n",
      "1 280648\n",
      "1 280847\n",
      "1 282745\n",
      "1 282867\n",
      "1 282919\n",
      "1 284450\n",
      "1 285287\n",
      "1 289084\n",
      "1 289091\n",
      "1 289847\n",
      "1 290629\n",
      "1 294011\n",
      "1 296403\n",
      "1 296719\n",
      "1 298645\n",
      "1 298739\n",
      "1 298888\n",
      "1 300498\n",
      "1 301880\n",
      "1 302262\n",
      "1 304148\n",
      "1 304473\n",
      "1 305250\n",
      "1 309676\n",
      "1 309780\n",
      "1 309813\n",
      "1 311279\n",
      "1 313227\n",
      "1 314996\n",
      "1 315421\n",
      "1 315483\n",
      "1 317127\n",
      "1 317139\n",
      "1 317807\n",
      "1 319734\n",
      "1 319866\n",
      "1 319919\n",
      "1 320088\n",
      "1 320107\n",
      "1 320246\n",
      "1 320393\n",
      "1 320512\n",
      "1 320775\n",
      "1 329793\n",
      "1 336259\n",
      "1 336645\n",
      "1 344878\n"
     ]
    }
   ],
   "source": [
    "for side in range(2):\n",
    "    for index in range(len(pred[side]['id'])):\n",
    "        last = [[2,1]]\n",
    "        acc = [[0,0,0]]\n",
    "        for word, bio, r in zip(tokenizer.convert_ids_to_tokens(pred[side]['id'][index].tolist()[1:]), pred[side]['bio'][index][1:], pred[side]['recover'][index].tolist()[1:]):\n",
    "            if(bio==0 and r>0 and word[:2]=='##'):\n",
    "                for _ in last:\n",
    "                    pass\n",
    "                    if(_[0] == 0 or _[1] =='.'):\n",
    "                        break\n",
    "                else:\n",
    "                    print(side, index)\n",
    "            #if(r>0):\n",
    "            #    last.append([bio, word])\n",
    "            if(r==0):\n",
    "                last = [[bio, word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so clearly , we are living in a time where we feel justified to hate on \" illegals \" . the solution that the president-elect has been talking about for years is a giant wall on the us southern border . i see this solution as such :', \"i have a giant block of cheese sitting in the middle of my house . mice will not stop getting into my house and eating this block of cheese ( i do't think mice are really into cheese like this , but i can't think of a better analogy at the moment ) . so my idea is to leave the block of cheese and try catching the mice and releasing them back outside my house . of course , they know the cheese is there and they keep coming for the cheese .\", 'the problem with undocumented workers coming into the country to take jobs is that there is someone offering these jobs to undocumented workers . construction crews , agriculture , etc. , are all industries where the leaders can save a whole lot of money by having undocumented workers , pay them salaries below minimum wage , offer no benefits , and threaten to have them deported .', \"what i think we should do is go after these people . if instead of a giant wall and an insane increase in a task force , it would be a lot cheaper to have a regulative authority that regularly audits and investigates companies that engage in this practice . and companies that are found engaging in it should face severe punishment ... .i 'm talking massive fines for first offense and revoking of business licenses in other offenses , potentially increasing to the point of confiscating the business and property .\", 'i assume that there is already a bit of a penalty in place for these employers , but the risk of getting caught must still be cheaper than the cost of only hiring american workers at decent wages .', \"edit : okay everyone , i object to using the word illegal to describe an entire group of people . it 's insensitive , offensive , and in the context , racist . ( link )\", \"edit 2 : let me clarify my personal views . i think this country needs more immigration , not less . i think we need open borders and that we 're moving towards globalization and overall , we need to move away from the idea of american superiority . i truly do't believe that illegal immigration is a problem severe enough to warrant building a massive wall , though i do concede that it may be easier to try to keep people out than to try to regulate business . my main issue is the republican talking point , and one of the cornerstones of the president-elect 's campaign that blames undocumented workers for taking american jobs and making the country less safe . and i do believe that even though it 's not an easy thing to do , we should be working more to fight the people that wish to exploit desperate people than the people willing to do anything to improve the lives of their family .\", \"> hello , users of cmv ! this is a footnote from your moderators . we 'd just like to remind you of a couple of things . firstly , please remember to read through our rules ( link ) . if you see a comment that has broken one , it is more effective to report it than downvote it . speaking of which , downvotes do't change views ( link ) ! if you are thinking about submitting a cmv yourself , please have a look through our popular topics wiki ( link ) first . any questions or concerns ? feel free to message us ( link ) . happy cmving !\"]\n"
     ]
    }
   ],
   "source": [
    "for _ in clean_posts[0]:\n",
    "    if( _['uid']=='4_0'):\n",
    "        print(_['context'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"you are giving way too much power to the american president . it 's just a person with little power . the system behind him/her is much stronger and much more powerful . any drastic measure that goes against the stability and harmony of the system ( like using nuclear weapons ) would be stopped before it happened .\",\n",
       " \"the us will absolutely not go into civil war because its economy is performing well . if there 's jobs and economical prosperity , there 's no need for war . trump supporters are loud , but they are weak willed and minded . if he looses they 'll just go back home .\"]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_posts[0][3589]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 what\n",
      "0 1 i\n",
      "0 1 think\n",
      "0 1 we\n",
      "0 1 should\n",
      "0 1 do\n",
      "0 1 is\n",
      "0 1 go\n",
      "0 1 after\n",
      "0 1 these\n",
      "0 1 people\n",
      "0 2 .\n",
      "0 0 if\n",
      "0 1 instead\n",
      "0 1 of\n",
      "0 1 a\n",
      "0 1 giant\n",
      "0 1 wall\n",
      "0 1 and\n",
      "0 1 an\n",
      "0 1 insane\n",
      "0 1 increase\n",
      "0 1 in\n",
      "0 1 a\n",
      "0 1 task\n",
      "0 1 force\n",
      "0 1 ,\n",
      "0 1 it\n",
      "0 1 would\n",
      "0 1 be\n",
      "0 1 a\n",
      "0 1 lot\n",
      "0 1 cheaper\n",
      "0 1 to\n",
      "0 1 have\n",
      "0 1 a\n",
      "0 1 reg\n",
      "1 1 ##ula\n",
      "2 1 ##tive\n",
      "0 1 authority\n",
      "0 1 that\n",
      "0 1 regularly\n",
      "0 1 audit\n",
      "1 1 ##s\n",
      "0 1 and\n",
      "0 1 investigates\n",
      "0 1 companies\n",
      "0 1 that\n",
      "0 1 engage\n",
      "0 1 in\n",
      "0 1 this\n",
      "0 1 practice\n",
      "0 2 .\n",
      "0 2 and\n",
      "0 0 companies\n",
      "0 1 that\n",
      "0 1 are\n",
      "0 1 found\n",
      "0 1 engaging\n",
      "0 1 in\n",
      "0 1 it\n",
      "0 1 should\n",
      "0 1 face\n",
      "0 1 severe\n",
      "0 1 punishment\n",
      "0 2 .\n",
      "1 2 .\n",
      "2 2 .\n",
      "0 2 .\n",
      "1 0 i\n",
      "0 1 '\n",
      "1 1 m\n",
      "0 1 talking\n",
      "0 1 massive\n",
      "0 1 fines\n",
      "0 1 for\n",
      "0 1 first\n",
      "0 1 offense\n",
      "0 1 and\n",
      "0 1 rev\n",
      "1 1 ##oki\n",
      "2 1 ##ng\n",
      "0 1 of\n",
      "0 1 business\n",
      "0 1 licenses\n",
      "0 1 in\n",
      "0 1 other\n",
      "0 1 offenses\n",
      "0 1 ,\n",
      "0 1 potentially\n",
      "0 1 increasing\n",
      "0 1 to\n",
      "0 1 the\n",
      "0 1 point\n",
      "0 1 of\n",
      "0 1 con\n",
      "1 1 ##fi\n",
      "2 1 ##sca\n",
      "3 1 ##ting\n",
      "0 1 the\n",
      "0 1 business\n",
      "0 1 and\n",
      "0 1 property\n",
      "0 2 .\n",
      "2 2 [SEP]\n"
     ]
    }
   ],
   "source": [
    "side, index = 0, 443\n",
    "for word, bio, r in zip(tokenizer.convert_ids_to_tokens(pred[side]['id'][index].tolist()[1:]), pred[side]['bio'][index][1:], pred[side]['recover'][index].tolist()[1:]):\n",
    "    print(r,bio,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
